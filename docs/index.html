<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="None">
        
        
        <link rel="shortcut icon" href="img/favicon.ico">
        <title>Microsoft Applied Robotics Research Library: LabanotationSuite</title>
        <link href="css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="css/font-awesome.min.css" rel="stylesheet">
        <link href="css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script src="js/jquery-1.10.2.min.js" defer></script>
        <script src="js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body class="homepage">

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <a class="navbar-brand" href=".">Microsoft Applied Robotics Research Library: LabanotationSuite</a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#microsoft-applied-robotics-research-library">Microsoft Applied Robotics Research Library</a></li>
            <li><a href="#open-source-samples-for-service-robotics">Open Source Samples for Service Robotics</a></li>
        <li class="main "><a href="#labanotation-suite">Labanotation Suite</a></li>
            <li><a href="#contributing">Contributing</a></li>
            <li><a href="#robot-gesture-authoring-system-description">Robot Gesture Authoring System Description</a></li>
            <li><a href="#gesture-authoring-tools">Gesture Authoring Tools</a></li>
            <li><a href="#faq">FAQ</a></li>
            <li><a href="#citation">Citation</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h2 id="microsoft-applied-robotics-research-library"><img alt="logo" src="img/MARR_logo.png" /> <a href="https://microsoft.github.io/AppliedRoboticsResearchLibrary/">Microsoft Applied Robotics Research Library</a></h2>
<h3 id="open-source-samples-for-service-robotics">Open Source Samples for Service Robotics</h3>
<p><a href="https://opensource.org/licenses/MIT"><img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-yellow.svg" /></a>  </p>
<h1 id="labanotation-suite">Labanotation Suite</h1>
<p><strong>Authors:</strong> David Baumert, Zhaoyuan Ma, John Lee, Sven Pleyer, Takuya Kiyokawa, Katsushi Ikeuchi</p>
<p>This Labanotation Suite repository contains a robot gesture authoring system comprised of software tools, source code, simulation software and sample data that supports experimentation with the concepts presented in the paper <strong><a href="https://link.springer.com/article/10.1007%2Fs11263-018-1123-1">Describing Upper-Body Motions Based on Labanotation for Learning-from-Observation Robots</a> (International Journal of Computer Vision, December 2018)</strong>. This suite can be used to help robots gesture in natural and meaningful ways.</p>
<h2 id="contributing">Contributing</h2>
<p>This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.</p>
<p>When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.</p>
<p>This project has adopted the <a href="https://opensource.microsoft.com/codeofconduct/">Microsoft Open Source Code of Conduct</a>.
For more information see the <a href="https://opensource.microsoft.com/codeofconduct/faq/">Code of Conduct FAQ</a> or
contact <a href="mailto:opencode@microsoft.com">opencode@microsoft.com</a> with any additional questions or comments.</p>
<h2 id="robot-gesture-authoring-system-description">Robot Gesture Authoring System Description</h2>
<h3 id="system-modules">System Modules:</h3>
<p><img alt="LabanSuite_Modules.jpg" src="img/LabanSuite_Modules.jpg" /></p>
<h3 id="system-diagram">System Diagram:</h3>
<p><img alt="LabanSuite_BlockDiagram.jpg" src="img/LabanSuite_BlockDiagram.jpg" /></p>
<h2 id="gesture-authoring-tools">Gesture Authoring Tools</h2>
<h3 id="kinectreader"><a href="GestureAuthoringTools/KinectReader/">KinectReader</a></h3>
<p>A Windows application that connects to a Kinect sensor device and provides a user interface for capturing and storing gestures performed by human subjects. It's primary output data is human stick-figure joint positions in a .csv format, but can also capture corresponding RGB video and audio at the same time.</p>
<h3 id="kinectcaptureeditor"><a href="GestureAuthoringTools/KinectCaptureEditor/">KinectCaptureEditor</a></h3>
<p>A Windows application that loads human joint position .csv files produced by the KinectReader or other Gesture Authoring Tools, as well as optional corresponding video and audio files. It provides a timeline-based method to edit audio and joint movement sequences into meaningful gestures.</p>
<h3 id="labaneditor"><a href="/GestureAuthoringTools/LabanEditor/">LabanEditor</a></h3>
<p>A Python script application that loads a Kinect joint .csv file representing a human gesture, provides algorithmic options for automatically extracting keyframes from the gesture that correspond Labanotation data, and provides a graphical user interface for selection and modification of the extracted keyframes. Additionally, it saves the resulting gesture data in a .json file format suitable for controlling robots running a gesture interpretation driver, as well as .png graphic file renderings of the charts and diagrams used in the interface.</p>
<h3 id="msrabot-simulation-software"><a href="MSRAbotSimulation/">MSRAbot Simulation Software</a></h3>
<p>A ready-to-run file tree that can be added to an HTTP server and viewed by most modern web browsers. The files implement a javascript simulation environment that hosts an animated model of the MSRAbot humanoid robot, along with viewing controls and an ability to render new JSON gesture files created using the Gesture Authoring Tools in this repository.</p>
<h2 id="faq">FAQ</h2>
<ul>
<li>
<p><strong>Q</strong> <em>Who should I contact regarding this repository?</em></p>
</li>
<li>
<p><strong>A</strong> Please create a Github issue or email <a href="mailto:robotics@microsoft.com">robotics@microsoft.com</a> with any questions or feedback.</p>
</li>
<li>
<p><strong>Q</strong> <em>Is this code suitable for non-robotic applications such as documenting dance steps?</em></p>
</li>
<li>
<p><strong>A</strong> Currently, the gesture capture system only addresses movement of the upper human torso.  However, we may expand to capturing the entire human skeleton in the future.</p>
</li>
</ul>
<h2 id="citation">Citation</h2>
<p>If you want to cite this work, please use the following bibtex code</p>
<pre><code>@Article{Ikeuchi2018,
author=&quot;Ikeuchi, Katsushi
and Ma, Zhaoyuan
and Yan, Zengqiang
and Kudoh, Shunsuke
and Nakamura, Minako&quot;,
title=&quot;Describing Upper-Body Motions Based on Labanotation for Learning-from-Observation Robots&quot;,
journal=&quot;International Journal of Computer Vision&quot;,
year=&quot;2018&quot;,
month=&quot;Dec&quot;,
day=&quot;01&quot;,
volume=&quot;126&quot;,
number=&quot;12&quot;,
pages=&quot;1415--1429&quot;,
issn=&quot;1573-1405&quot;,
doi=&quot;10.1007/s11263-018-1123-1&quot;,
url=&quot;https://doi.org/10.1007/s11263-018-1123-1&quot;
}
</code></pre></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = ".",
                shortcuts = {"search": 83, "next": 78, "help": 191, "previous": 80};
        </script>
        <script src="js/base.js" defer></script>
        <script src="search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>

<!--
MkDocs version : 1.0.4
Build Date UTC : 2021-05-27 06:51:28
-->
